{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "agFC1rsDJ96_"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IpC5jwkPNogX"
   },
   "outputs": [],
   "source": [
    "def create_filters(n, s) :\n",
    "      return np.zeros((n, s, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_ojkH75wNo0s"
   },
   "outputs": [],
   "source": [
    "conv_1_filter = create_filters(32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YbXGbNzGLVXO"
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "H3Brw5xgNLb4"
   },
   "outputs": [],
   "source": [
    "set1 = unpickle(\"./content/data_batch_1\")\n",
    "set2 = unpickle(\"./content/data_batch_2\")\n",
    "set3 = unpickle(\"./content/data_batch_3\")\n",
    "set4 = unpickle(\"./content/data_batch_4\")\n",
    "set5 = unpickle(\"./content/data_batch_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "u0udMbn8nMA9"
   },
   "outputs": [],
   "source": [
    "x_train = np.vstack((set1[b'data'], set2[b'data'], set3[b'data'], set4[b'data'], set5[b'data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ss9Bg1rlnr2h",
    "outputId": "d86b28c8-7ead-4a73-9679-44b6f6e7fbe1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3072)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-h03qEttpnI6"
   },
   "outputs": [],
   "source": [
    "y_train = np.hstack((np.array(set1[b'labels']), np.array(set2[b'labels']), np.array(set3[b'labels']), np.array(set4[b'labels']) ,np.array(set5[b'labels']) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mEZfGicpqUoB",
    "outputId": "9231db9a-01ca-4e62-e69c-30d11f548e26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "1FSSfOPlrl2d"
   },
   "outputs": [],
   "source": [
    "def convolution(sample, kernel):\n",
    "    # assert len(sample.shape) == len(kernel.shape) - 1 # check that the filter and sample dimensions match \n",
    "\n",
    "    kernel_size = kernel.shape[1]\n",
    "    size_feature_map = sample.shape[1] - kernel.shape[1] + 1 # output dimension for valid convolution\n",
    "    n_out_channels = kernel.shape[0] # number of output channels is the number of filters (for now)\n",
    "\n",
    "    #now we perform the convolution\n",
    "\n",
    "    # initializing the output tensor to zeros\n",
    "    output_tensor = create_filters(n_out_channels, size_feature_map)\n",
    "\n",
    "    # loop for all the kernels\n",
    "    for i in range(n_out_channels):\n",
    "        current_kernel = kernel[i] # get the required kernel\n",
    "\n",
    "    for r in range(size_feature_map): # for the rows\n",
    "        for c in range(size_feature_map): # for the columns\n",
    "            window = sample[:, r : r + kernel_size, c : c + kernel_size] #take the window\n",
    "            value = np.sum(window*current_kernel, axis = None) # multiply with the kernel and sum  up the value\n",
    "            output_tensor[i, r, c] = value # update the result tensor\n",
    "\n",
    "    return output_tensor # return the result tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "GDWAnWcyyZvt"
   },
   "outputs": [],
   "source": [
    "a = np.array(([[1, 1, 2, 4], [1, -1, 1, -1], [1, 1, 1, 1], [1, -1, 1, -1]], [[2, 2, 2, 0], [2, 0, 2, 2], [0, 2, 2, 2], [2, 2, 0, 2]], [[3, 3, 3, 3], [30, 3, 3, 30], [3, 3, 3, -5], [3, 3, 3, -5]]))\n",
    "b = np.array(([[[5,5], [5, 5]], [[5,5], [5, 5]], [[5,5], [5, 5]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.array(([[5,5], [5, 5]]))\n",
    "beta = np.array(([5,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "object too deep for desired array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconvolve\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/numpy/core/numeric.py:851\u001b[0m, in \u001b[0;36mconvolve\u001b[0;34m(a, v, mode)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(v) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv cannot be empty\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 851\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmultiarray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrelate\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: object too deep for desired array"
     ]
    }
   ],
   "source": [
    "np.convolve(alpha, beta, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3R7U0r_Z0K27",
    "outputId": "794f594c-1ada-453d-f277-400364560fc4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[235., 105., 255.],\n",
       "        [225., 100., 205.],\n",
       "        [100., 100.,  20.]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolution(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "HCYkJ-J-Ds8A"
   },
   "outputs": [],
   "source": [
    "def relu(map):    \n",
    "    output_tensor = np.maximum(map, 0)\n",
    "    return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GH55O1zmGM99",
    "outputId": "27056b76-54fa-4a8e-cd53-c2931c7a8c9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  1,  2,  4],\n",
       "        [ 1,  0,  1,  0],\n",
       "        [ 1,  1,  1,  1],\n",
       "        [ 1,  0,  1,  0]],\n",
       "\n",
       "       [[ 2,  2,  2,  0],\n",
       "        [ 2,  0,  2,  2],\n",
       "        [ 0,  2,  2,  2],\n",
       "        [ 2,  2,  0,  2]],\n",
       "\n",
       "       [[ 3,  3,  3,  3],\n",
       "        [30,  3,  3, 30],\n",
       "        [ 3,  3,  3,  0],\n",
       "        [ 3,  3,  3,  0]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AebNe7oiIymE",
    "outputId": "533473ad-225f-4822-f65d-fc5cdae4b464"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8NNjqSXyGXIw",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def max_pooling(map, dim):\n",
    "  n_channels = map.shape[0]\n",
    "  map_size = int(map.shape[1])\n",
    "  output_size = int(map.shape[1]/2)\n",
    "\n",
    "  output_tensor = create_filters(n_channels, output_size)\n",
    "\n",
    "  for i in range(n_channels):\n",
    "    for r in range(output_size):\n",
    "      for c in range(output_size):\n",
    "        output_tensor[i, r, c] = np.max(map[i, 2*r : 2*r + dim, 2*c : 2*c + dim])\n",
    "\n",
    "  return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling_forward(map, dim):\n",
    "    n_channels = map.shape[0]\n",
    "    \n",
    "    map_size = map.shape[1]\n",
    "    output_size = map.shape[1]//dim\n",
    "\n",
    "    return map.reshape(n_channels, output_size, dim, output_size, dim).max(axis=(2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gypwA5brJHd1",
    "outputId": "e1d49e35-899b-4372-aece-6cb820a65a98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  4],\n",
       "        [ 1,  1]],\n",
       "\n",
       "       [[ 2,  2],\n",
       "        [ 2,  2]],\n",
       "\n",
       "       [[30, 30],\n",
       "        [ 3,  3]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooling_forward(a, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6WxRAuLtJKBR"
   },
   "outputs": [],
   "source": [
    "def softmax(v):\n",
    "  output = np.exp(v)\n",
    "  final_output = output/(np.sum(output))\n",
    "  return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06dnpKhq7Mah",
    "outputId": "afcc1be4-8f37-4b1b-b746-e941cf6746fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09003057, 0.24472847, 0.66524096])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(np.array(([1,2,3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mQviogjB7XG-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
