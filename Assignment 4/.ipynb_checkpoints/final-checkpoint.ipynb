{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a596da8-027d-4479-95cb-006662857d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a22f59f9-1a55-4858-8ca2-38f228afe7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(v):\n",
    "    return (v - np.mean(v))/np.std(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd2a6121-4709-498a-9067-bcd297bb2085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(v):\n",
    "    v = v - np.max(v, axis = 1).reshape(-1,1)\n",
    "    exp_array = np.exp(v)\n",
    "    return exp_array / np.sum(exp_array, axis = 1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7081392f-e993-416a-a851-90cd55a7b779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_filter(n, s):\n",
    "      return np.zeros((n, s, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e13dfe0-2ec6-4a9a-8a85-f9f48f6f54ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(map):    \n",
    "    output_tensor = np.maximum(map, 0)\n",
    "    return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01da5f94-46ab-4e6b-9edf-725d45ab4fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pad(sample, pad):\n",
    "    n_sample, n, h, w = sample.shape\n",
    "    \n",
    "    out_sample = np.zeros((n_sample, n,h+2*pad,w+2*pad))\n",
    "    \n",
    "    out_sample[:, :, pad: -pad, pad : -pad] = sample\n",
    "    return out_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82c7aef5-4095-4f08-8619-e58a44ca6a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling(map, dim):\n",
    "    n_sample = map.shape[0]\n",
    "    n_channels = map.shape[1]\n",
    "    map_size = map.shape[2]\n",
    "    output_size = map.shape[2]//dim\n",
    "\n",
    "    return map.reshape(n_sample, n_channels, output_size, dim, output_size, dim).max(axis=(3,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9312f736-65c4-4890-b180-c0478920ef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution(sample, kernel):\n",
    "    kernel_size = kernel.shape[1]\n",
    "    pad = kernel_size//2\n",
    "    n_sample, n, h, w = sample.shape\n",
    "\n",
    "    sample = add_pad(sample, pad)\n",
    "    \n",
    "    size_feature_map = h\n",
    "    n_out_channels = kernel.shape[0]\n",
    "\n",
    "    output_tensor = np.zeros((n_sample, n_out_channels, size_feature_map, size_feature_map))\n",
    "\n",
    "    for i in range(n_out_channels):\n",
    "        current_kernel = kernel[i]\n",
    "\n",
    "        for r in range(size_feature_map):\n",
    "            for c in range(size_feature_map):\n",
    "                window = sample[:, :, r : r + kernel_size, c : c + kernel_size]\n",
    "                value = np.sum(window*current_kernel, axis = (1,2,3))\n",
    "                output_tensor[:, i, r, c] = value\n",
    "\n",
    "    return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3c6413f-561e-4ce0-97da-c49ecc06cd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_convolution(sample, kernel, pad):\n",
    "    kernel_size = kernel.shape[1]\n",
    "    n_sample, n, h, w = sample.shape\n",
    "    sample = add_pad(sample, pad)\n",
    "    \n",
    "    size_feature_map = h + 2*pad - kernel_size + 1\n",
    "    n_out_channels = kernel.shape[0]\n",
    "\n",
    "    output_tensor = np.zeros((n_sample, n_out_channels, size_feature_map, size_feature_map))\n",
    "\n",
    "    for i in range(n_out_channels):\n",
    "        current_kernel = kernel[i]\n",
    "\n",
    "        for r in range(size_feature_map):\n",
    "            for c in range(size_feature_map):\n",
    "                window = sample[:, :, r : r + kernel_size, c : c + kernel_size]\n",
    "                value = np.sum(window*current_kernel, axis = (1,2,3))\n",
    "                output_tensor[:, i, r, c] = value\n",
    "\n",
    "    return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f205a152-a7d3-4fe4-a2a6-f0144d6a6310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def another_convolution(sample, kernel, pad):\n",
    "    kernel_size = kernel.shape[1]\n",
    "    n, h, w = sample.shape\n",
    "    sample = add_pad(sample, pad)\n",
    "    \n",
    "    size_feature_map = h + 2*pad - kernel_size + 1\n",
    "    n_out_channels = kernel.shape[0]\n",
    "\n",
    "    output_tensor = np.zeros((n_sample, n_out_channels, size_feature_map, size_feature_map))\n",
    "\n",
    "    for i in range(n_out_channels):\n",
    "        current_kernel = kernel[i]\n",
    "\n",
    "        for r in range(size_feature_map):\n",
    "            for c in range(size_feature_map):\n",
    "                window = sample[:, :, r : r + kernel_size, c : c + kernel_size]\n",
    "                value = np.sum(window*current_kernel, axis = (1,2,3))\n",
    "                output_tensor[:, i, r, c] = value\n",
    "\n",
    "    return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4831a188-56a4-4fa6-ba96-f14ee36989af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_convolve2d(sample, kernel):\n",
    "    n, h, w = sample.shape\n",
    "    kernel_size = kernel.shape[1]\n",
    "    pad = kernel_size//2\n",
    "    \n",
    "    out_sample = np.zeros((n, h, w))\n",
    "    \n",
    "    for k in range(n):\n",
    "        curr_sample = sample[k]\n",
    "        padded_sample = np.pad(curr_sample, ((pad,pad), (pad,pad)), 'constant')\n",
    "        # print(padded_sample)\n",
    "\n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                out_sample[k, i, j] = np.sum(kernel * padded_sample[i:i+kernel_size, j:j+kernel_size])\n",
    "    \n",
    "    return out_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e251f3d2-b0dc-4cab-97d4-ecedef473800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 30.,  87.],\n",
       "        [ 87., 195.]],\n",
       "\n",
       "       [[ 30.,  87.],\n",
       "        [ 87., 195.]],\n",
       "\n",
       "       [[ 30.,  87.],\n",
       "        [ 87., 195.]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[[1,2], [3,4]], [[1,2], [3,4]], [[1,2], [3,4]]])\n",
    "b = np.array([[[0,-1], [9,10]], [[0,-1], [9,10]], [[0,-1], [9,10]]])\n",
    "full_convolve2d(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13f8f060-98b8-4275-a4f7-8feb6f6c015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv2d:\n",
    "    def __init__(self, num, size):\n",
    "        self.kernel = np.random.randn(num, size, size)/9 # Xavier Initialisation\n",
    "        self.bias = np.random.rand(num, size, size)/9\n",
    "        self.layer_input = None\n",
    "        self.layer_output = None\n",
    "        self.layer_activated = None\n",
    "        self.kernel_grad = None\n",
    "        self.size = size\n",
    "    \n",
    "    def forward_pass(self, sample): # DONE\n",
    "        self.layer_input = sample\n",
    "\n",
    "        output_tensor = convolution(sample, self.kernel)\n",
    "    \n",
    "        self.layer_output = output_tensor\n",
    "        self.layer_activated = relu(output_tensor) # relu is totally fine\n",
    "        \n",
    "        return self.layer_activated # return the result tensor\n",
    "        \n",
    "    def backward_pass(self, inp_grad): # DONE\n",
    "        n_sample, n, h, w = self.layer_input.shape\n",
    "        pass_grad = np.zeros((n_sample, n, h, w))\n",
    "        \n",
    "        relu_mat = self.layer_activated\n",
    "        relu_mat[np.nonzero(relu_mat)] = 1\n",
    "        \n",
    "        inp_grad = inp_grad * relu_mat # must be dimensionally equivalent\n",
    "        \n",
    "        # other_grad = np.sum(inp_grad, axis = 0)/32\n",
    "        nk, hk, wk = self.kernel.shape\n",
    "        kernel_grad = np.zeros((n_sample, nk, hk, wk))\n",
    "        for i in range(n_sample):\n",
    "            curr_grad = inp_grad[i]\n",
    "            kernel_grad[i] = other_convolution(self.layer_input[i].reshape(1, n, h, w), curr_grad, self.size//2)[0]\n",
    "        self.kernel_grad = np.sum(kernel_grad, axis = 0)/32\n",
    "        \n",
    "        pass_grad = np.zeros((n_sample, n, h, w))\n",
    "        flip_kernel = np.flip(self.kernel, axis=(1,2))\n",
    "        \n",
    "        for i in range(n_sample):\n",
    "            curr_grad = inp_grad[i]    \n",
    "            not_final = full_convolve2d(curr_grad, flip_kernel)\n",
    "            still_not_final = np.sum(not_final, axis = 0)\n",
    "            for j in range(n):\n",
    "                pass_grad[i, j] = still_not_final\n",
    "        \n",
    "        return pass_grad\n",
    "        \n",
    "    def update(self): # DONE\n",
    "        # print(self.kernel_grad.shape)\n",
    "        self.kernel -= 0.01*self.kernel_grad # applying gradient descent\n",
    "        return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c90d2bd6-82bd-4a9b-8cf7-e24433d0e556",
   "metadata": {},
   "outputs": [],
   "source": [
    "class maxpool2d:\n",
    "    def __init__(self, dim):\n",
    "        self.dim = dim\n",
    "        self.layer_input = None\n",
    "        self.layer_output = None\n",
    "        \n",
    "    def forward_pass(self , sample):\n",
    "        self.layer_input = sample\n",
    "        self.layer_output = pooling(sample, 2)\n",
    "        return self.layer_output\n",
    "\n",
    "    def backward_pass(self, inp_grad):\n",
    "        n_sample, n, h, w = self.layer_input.shape\n",
    "        x = self.layer_input\n",
    "        \n",
    "        pass_mat = np.zeros((n_sample, n, h, w))\n",
    "        \n",
    "        for i in range(h//2):\n",
    "            for j in range(w//2):\n",
    "                h_start = i * 2\n",
    "                h_end = h_start + 2\n",
    "                w_start = j * 2\n",
    "                w_end = w_start + 2\n",
    "                \n",
    "                X = self.layer_input\n",
    "                X_pool = X[:, :, h_start:h_end, w_start:w_end]\n",
    "                mask = (X_pool == np.max(X_pool, axis=(2, 3))[:, :, None, None])\n",
    "                pass_mat[:, :, h_start:h_end, w_start:w_end] += mask * (inp_grad[:, :, i, j])[:, :, None, None]\n",
    "            \n",
    "        return pass_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f11c194-63c0-4de5-889d-94710e61f1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fc_1:\n",
    "    def __init__(self, size, next_size, batch_size = 32):\n",
    "        self.weights = np.random.randn(next_size, size)/4096\n",
    "        self.bias = np.random.randn(1, next_size)/4096\n",
    "        self.weights_grad = None\n",
    "        self.bias_grad = None\n",
    "        self.layer_input = None\n",
    "        self.layer_output = None\n",
    "        self.layer_output_active = None\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def forward_pass(self, sample):\n",
    "        self.layer_input = sample\n",
    "        \n",
    "        output = sample @ self.weights.T + self.bias # this is fine\n",
    "        self.layer_output = output\n",
    "        self.layer_output_active = relu(output)\n",
    "        \n",
    "        return self.layer_output_active\n",
    "    \n",
    "    def backward_pass(self, inp_grad):\n",
    "        relu_mat = self.layer_output_active\n",
    "        relu_mat[np.nonzero(relu_mat)] = 1\n",
    "        relued_grad = inp_grad * relu_mat\n",
    "        \n",
    "        # print(\"here\", relued_grad.shape)\n",
    "        \n",
    "        pass_grad = relued_grad @ self.weights\n",
    "        \n",
    "        weights_grad = np.zeros((self.batch_size, 64, 4096))\n",
    "        for i in range(self.batch_size):\n",
    "            weights_grad[i] = relued_grad[i].reshape(-1,1) @ self.layer_input[i].reshape(1,-1)\n",
    "        self.weights_grad = np.sum(weights_grad, axis = 0)/self.batch_size\n",
    "        \n",
    "        self.bias_grad = np.sum(relued_grad, axis = 0)/self.batch_size\n",
    "        \n",
    "        return pass_grad\n",
    "    \n",
    "    def update(self):\n",
    "        self.weights -= 0.01*self.weights_grad\n",
    "        self.bias -= 0.01*self.bias_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12c47614-e2f5-4ff4-963c-a259cf130fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fc_2:\n",
    "    def __init__(self, size, next_size, batch_size = 32):\n",
    "        self.weights = np.random.randn(next_size, size)/64\n",
    "        self.bias = np.random.randn(1, next_size)/64\n",
    "        self.weights_grad = None\n",
    "        self.bias_grad = None\n",
    "        self.layer_input = None\n",
    "        self.layer_output = None\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def forward_pass(self, sample):\n",
    "        self.layer_input = sample\n",
    "        output = sample @ self.weights.T + self.bias\n",
    "        self.layer_output = output\n",
    "        return self.layer_output\n",
    "    \n",
    "    def backward_pass(self, inp_grad):\n",
    "        pass_grad = inp_grad @ self.weights\n",
    "        \n",
    "        weights_grad = np.zeros((self.batch_size, 10, 64))\n",
    "        for i in range(self.batch_size):\n",
    "            weights_grad[i] = inp_grad[i].reshape(-1,1) @ self.layer_input[i].reshape(1,-1)\n",
    "        self.weights_grad = np.sum(weights_grad, axis = 0)/self.batch_size\n",
    "        \n",
    "        self.bias_grad = np.sum(inp_grad, axis = 0)/self.batch_size\n",
    "        \n",
    "        return pass_grad\n",
    "    \n",
    "    def update(self):\n",
    "        self.weights -= 0.01*self.weights_grad\n",
    "        self.bias -= 0.01*self.bias_grad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8605a4ce-ca78-46b0-b452-4d836531252c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 6],\n",
       "       [ 8],\n",
       "       [10],\n",
       "       [12]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_grad = np.zeros((2, 4, 3))\n",
    "inp_grad = np.array([[1,2,3,4], [5,6,7,8]])\n",
    "layer_input = np.array([[9,8,7], [-2,-3,-4]])\n",
    "print(inp_grad[0].reshape(-1,1).shape)\n",
    "\n",
    "for i in range(2):\n",
    "    weights_grad[i] = inp_grad[i].reshape(-1,1) @ layer_input[i].reshape(1,-1)\n",
    "alpha = np.sum(weights_grad, axis = 0)\n",
    "np.sum(inp_grad, axis = 0).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25a626e8-4a25-4d51-8ef7-980e89d39c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 7])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2], [4,5]])\n",
    "np.sum(a, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c7ad364-0eea-4c61-a1ce-139db454ccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6638e951-9124-4430-a40a-ca082ddfadac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 3072), (50000,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set1 = unpickle(\"./content/data_batch_1\")\n",
    "set2 = unpickle(\"./content/data_batch_2\")\n",
    "set3 = unpickle(\"./content/data_batch_3\")\n",
    "set4 = unpickle(\"./content/data_batch_4\")\n",
    "set5 = unpickle(\"./content/data_batch_5\")\n",
    "x_train = np.vstack((set1[b'data'], set2[b'data'], set3[b'data'], set4[b'data'], set5[b'data']))\n",
    "y_train = np.hstack((np.array(set1[b'labels']), np.array(set2[b'labels']), np.array(set3[b'labels']), np.array(set4[b'labels']) ,np.array(set5[b'labels']) ))\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bb5da4c-255d-424a-b9bd-4b7d34face3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trial = []\n",
    "y_trial = y_train[0:32]\n",
    "for i in range(32):\n",
    "    x_trial.append(x_train[i].reshape(3,32,32))\n",
    "x_trial = np.array(x_trial)\n",
    "y_trial = np.array(y_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "4db6b32d-7b2d-45d5-bcb1-bbd8ae630484",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = conv2d(32, 3)\n",
    "pool1 = maxpool2d(2)\n",
    "conv2 = conv2d(64, 5)\n",
    "pool2 = maxpool2d(2)\n",
    "conv3 = conv2d(64, 3)\n",
    "fc1 = fc_1(4096, 64)\n",
    "fc2 = fc_2(64, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "2108f8e3-6664-4608-9819-e760654ae2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = x_train[0:32].reshape(32,3,32,32)\n",
    "y = y_train[0:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "a8a854af-f923-453d-a99a-d838d5e7d65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1:  (32, 32, 32, 32)\n",
      "a2:  (32, 32, 16, 16)\n",
      "a3:  (32, 64, 16, 16)\n",
      "a4:  (32, 64, 8, 8)\n",
      "a5:  (32, 4096)\n",
      "a6:  (32, 64)\n",
      "a7:  (32, 10)\n",
      "softmax:  (32, 10)\n",
      "grad_fc2:  (32, 10)\n",
      "grad_fc1:  (32, 64)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "a1 = conv1.forward_pass(img1)\n",
    "print(\"a1: \", a1.shape)\n",
    "# print(a1[0])\n",
    "\n",
    "a2 = pool1.forward_pass(a1)\n",
    "print(\"a2: \", a2.shape)\n",
    "# print(a2[0])\n",
    "\n",
    "a3 = conv2.forward_pass(a2)\n",
    "print(\"a3: \", a3.shape)\n",
    "# print(a3[0])\n",
    "\n",
    "a4 = pool2.forward_pass(a3)\n",
    "print(\"a4: \", a4.shape)\n",
    "# print(a4[0])\n",
    "\n",
    "a5 = conv3.forward_pass(a4).reshape(batch_size, 4096)\n",
    "print(\"a5: \", a5.shape)\n",
    "# print(a5[0])\n",
    "\n",
    "a6 = fc1.forward_pass(a5)\n",
    "print(\"a6: \", a6.shape)\n",
    "# print(a6[0])\n",
    "\n",
    "a7 = fc2.forward_pass(a6)\n",
    "print(\"a7: \", a7.shape)\n",
    "# print(a7[0])\n",
    "\n",
    "out = softmax(a7)\n",
    "print(\"softmax: \", out.shape)\n",
    "\n",
    "onehot = np.zeros((batch_size, 10))\n",
    "for i in range(batch_size):\n",
    "    onehot[i][y[i]] = 1\n",
    "grad_fc2 = out - onehot\n",
    "print(\"grad_fc2: \", grad_fc2.shape)\n",
    "\n",
    "grad_fc1 = fc2.backward_pass(grad_fc2)\n",
    "print(\"grad_fc1: \", grad_fc1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0630ca9-d21c-4467-bed9-9cba54f8c3f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bdb240-dcfc-4515-9c29-c508a0b4e12e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e14759-394e-4d81-aa3d-0ddc8f3ca036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4bd858-d014-459c-92f7-eb753a4054ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a40477e-34fd-424d-952f-ab3c79aefe80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbacf684-31b6-4937-9773-e2905be6ec83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d4dded-04d0-418f-93f0-63423aa73d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "7d47fefa-9003-4d40-adbb-6c3de45c49e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(x, y):\n",
    "    a1 = conv1.forward_pass(x)\n",
    "    a2 = pool1.forward_pass(a1)\n",
    "    a3 = conv2.forward_pass(a2)\n",
    "    a4 = pool2.forward_pass(a3)\n",
    "    \n",
    "    # cannot flatten this directly at this position\n",
    "    a5 = conv3.forward_pass(a4).reshape(32, 4096)\n",
    "    # print(a5.shape)\n",
    "    a6 = fc1.forward_pass(a5)\n",
    "    a7 = fc2.forward_pass(a6)\n",
    "    out = softmax(a7)\n",
    "    # print(out.shape)\n",
    "    # print(i, \"actual: \", y[i],  \"prediction: \", np.argmax(out))\n",
    "\n",
    "    onehot = np.zeros(10)\n",
    "    onehot[y] = 1\n",
    "    grad_fc2 = out - onehot\n",
    "    # print(grad_fc2.shape)\n",
    "\n",
    "    grad_fc1 = fc2.backward_pass(grad_fc2)\n",
    "    print(grad_fc1.shape)\n",
    "    grad_conv3 = fc1.backward_pass(grad_fc1).reshape(32, 64, 8, 8)\n",
    "    grad_pool2 = conv3.backward_pass(grad_conv3)\n",
    "    grad_conv2 = pool2.backward_pass(grad_pool2)\n",
    "    grad_pool1 = conv2.backward_pass(grad_conv2)\n",
    "    grad_conv1 = pool1.backward_pass(grad_pool1)\n",
    "    init_grad = conv1.backward_pass(grad_conv1)\n",
    "\n",
    "    fc2.update()\n",
    "    fc1.update()\n",
    "    conv3.update()\n",
    "    conv2.update()\n",
    "    conv1.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "3e3ccac5-63dd-4cd9-88c3-047e0bcdd90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6, 4, 3,\n",
       "       6, 6, 2, 6, 3, 5, 4, 0, 0, 9])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "7e39820d-eef9-43c0-9ad9-9c1ad3b2dff0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64)\n",
      "here (32, 64)\n",
      "18.447256088256836  seconds\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "run(x_trial, y_trial)\n",
    "print(time.time()-begin, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356bc7cb-1858-48a3-938e-843d61001781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4e1a0e-8599-4bc1-9d44-863f36d8746b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71fb73f-bd99-4559-bf12-e31a184c3d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66dcde5-0f04-4cc5-bf5c-4d2b63460c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc93eda3-45e4-431c-83ed-a3899e40be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = conv2d(32, 3)\n",
    "pool1 = maxpool2d(2)\n",
    "conv2 = conv2d(64, 5)\n",
    "pool2 = maxpool2d(2)\n",
    "conv3 = conv2d(64, 3)\n",
    "fc1 = fc_1(4096, 64)\n",
    "fc2 = fc_2(64, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "541944bd-bb59-43ec-acb3-505f360d102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(X, Y):\n",
    "    begin = time.time()\n",
    "    idx = np.random.randint(960, size=32)\n",
    "    \n",
    "    for i in range(30):\n",
    "        x = X[idx]\n",
    "        y = Y[idx]\n",
    "        \n",
    "        # print(x.shape)\n",
    "\n",
    "        x = x.reshape(32, 3, 32, 32)\n",
    "        \n",
    "        # print(x.shape)\n",
    "    \n",
    "        a1 = conv1.forward_pass(x)\n",
    "        a2 = pool1.forward_pass(a1)\n",
    "        a3 = conv2.forward_pass(a2)\n",
    "        a4 = pool2.forward_pass(a3)\n",
    "\n",
    "        # cannot flatten this directly at this position\n",
    "        a5 = conv3.forward_pass(a4).reshape(32, 4096)\n",
    "        # print(a5.shape)\n",
    "        a6 = fc1.forward_pass(a5)\n",
    "        a7 = fc2.forward_pass(a6)\n",
    "        out = softmax(a7)\n",
    "        # print(out.shape)\n",
    "        # print(i, \"actual: \", y[i],  \"prediction: \", np.argmax(out))\n",
    "\n",
    "        onehot = np.zeros((32, 10))\n",
    "        for j in range(32):\n",
    "            onehot[j][y[j]] = 1\n",
    "        grad_fc2 = out - onehot\n",
    "        # print(grad_fc2.shape)\n",
    "\n",
    "        grad_fc1 = fc2.backward_pass(grad_fc2)\n",
    "        grad_conv3 = fc1.backward_pass(grad_fc1).reshape(32, 64, 8, 8)\n",
    "        grad_pool2 = conv3.backward_pass(grad_conv3)\n",
    "        grad_conv2 = pool2.backward_pass(grad_pool2)\n",
    "        grad_pool1 = conv2.backward_pass(grad_conv2)\n",
    "        grad_conv1 = pool1.backward_pass(grad_pool1)\n",
    "        init_grad = conv1.backward_pass(grad_conv1)\n",
    "\n",
    "        fc2.update()\n",
    "        fc1.update()\n",
    "        conv3.update()\n",
    "        conv2.update()\n",
    "        conv1.update()\n",
    "        \n",
    "        prediction = np.argmax(out, axis = 1)\n",
    "        acc = np.sum(prediction == y)/32\n",
    "        \n",
    "        print(i, \"time: \", time.time()-begin, \" seconds\")\n",
    "        print(\"batch accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e72cb7c6-1b8d-4420-a274-a65e0114061f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 time:  17.548564910888672  seconds\n",
      "batch accuracy =  0.125\n",
      "1 time:  35.03215408325195  seconds\n",
      "batch accuracy =  0.0625\n",
      "2 time:  52.52545619010925  seconds\n",
      "batch accuracy =  0.09375\n",
      "3 time:  70.01437592506409  seconds\n",
      "batch accuracy =  0.125\n",
      "4 time:  87.49400806427002  seconds\n",
      "batch accuracy =  0.0625\n",
      "5 time:  104.96229100227356  seconds\n",
      "batch accuracy =  0.15625\n",
      "6 time:  122.4396460056305  seconds\n",
      "batch accuracy =  0.0625\n",
      "7 time:  139.91761994361877  seconds\n",
      "batch accuracy =  0.0625\n",
      "8 time:  157.99947118759155  seconds\n",
      "batch accuracy =  0.09375\n",
      "9 time:  175.62105798721313  seconds\n",
      "batch accuracy =  0.125\n",
      "10 time:  193.11893820762634  seconds\n",
      "batch accuracy =  0.0625\n",
      "11 time:  210.67724013328552  seconds\n",
      "batch accuracy =  0.03125\n",
      "12 time:  228.28853511810303  seconds\n",
      "batch accuracy =  0.125\n",
      "13 time:  245.8278729915619  seconds\n",
      "batch accuracy =  0.0625\n",
      "14 time:  263.5075452327728  seconds\n",
      "batch accuracy =  0.0625\n",
      "15 time:  281.0798919200897  seconds\n",
      "batch accuracy =  0.0625\n",
      "16 time:  298.7238130569458  seconds\n",
      "batch accuracy =  0.03125\n",
      "17 time:  316.299250125885  seconds\n",
      "batch accuracy =  0.0625\n",
      "18 time:  333.84445810317993  seconds\n",
      "batch accuracy =  0.0625\n",
      "19 time:  351.3385970592499  seconds\n",
      "batch accuracy =  0.03125\n",
      "20 time:  368.87286925315857  seconds\n",
      "batch accuracy =  0.125\n",
      "21 time:  386.4582369327545  seconds\n",
      "batch accuracy =  0.1875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msgd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 36\u001b[0m, in \u001b[0;36msgd\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m     34\u001b[0m grad_fc1 \u001b[38;5;241m=\u001b[39m fc2\u001b[38;5;241m.\u001b[39mbackward_pass(grad_fc2)\n\u001b[1;32m     35\u001b[0m grad_conv3 \u001b[38;5;241m=\u001b[39m fc1\u001b[38;5;241m.\u001b[39mbackward_pass(grad_fc1)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m grad_pool2 \u001b[38;5;241m=\u001b[39m \u001b[43mconv3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_conv3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m grad_conv2 \u001b[38;5;241m=\u001b[39m pool2\u001b[38;5;241m.\u001b[39mbackward_pass(grad_pool2)\n\u001b[1;32m     38\u001b[0m grad_pool1 \u001b[38;5;241m=\u001b[39m conv2\u001b[38;5;241m.\u001b[39mbackward_pass(grad_conv2)\n",
      "Cell \u001b[0;32mIn[13], line 43\u001b[0m, in \u001b[0;36mconv2d.backward_pass\u001b[0;34m(self, inp_grad)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_sample):\n\u001b[1;32m     42\u001b[0m     curr_grad \u001b[38;5;241m=\u001b[39m inp_grad[i]    \n\u001b[0;32m---> 43\u001b[0m     not_final \u001b[38;5;241m=\u001b[39m \u001b[43mfull_convolve2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurr_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflip_kernel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     still_not_final \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(not_final, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m, in \u001b[0;36mfull_convolve2d\u001b[0;34m(sample, kernel)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(h):\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(w):\n\u001b[0;32m---> 15\u001b[0m             out_sample[k, i, j] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpadded_sample\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m:\u001b[49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_sample\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2183\u001b[0m, in \u001b[0;36m_sum_dispatcher\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2113\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2114\u001b[0m \u001b[38;5;124;03m    Clip (limit) the values in an array.\u001b[39;00m\n\u001b[1;32m   2115\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2178\u001b[0m \n\u001b[1;32m   2179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m'\u001b[39m, a_min, a_max, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 2183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum_dispatcher\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2184\u001b[0m                     initial\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, out)\n\u001b[1;32m   2188\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_sum_dispatcher)\n\u001b[1;32m   2189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2190\u001b[0m         initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sgd(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875cb58f-32ac-4fbe-8086-ddd7edd22d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab8662e6-8dfa-48b0-8b40-55ba077cb374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.65051499e+45 6.65069833e+45 6.65063137e+45 6.65071633e+45\n",
      "  6.65051469e+45 6.65055012e+45 6.65052601e+45 6.65063294e+45\n",
      "  6.65058867e+45 6.65056834e+45]\n",
      " [6.09307724e+45 6.09324522e+45 6.09318387e+45 6.09326171e+45\n",
      "  6.09307696e+45 6.09310942e+45 6.09308733e+45 6.09318530e+45\n",
      "  6.09314474e+45 6.09312612e+45]\n",
      " [7.40534554e+45 7.40554969e+45 7.40547513e+45 7.40556973e+45\n",
      "  7.40534520e+45 7.40538465e+45 7.40535781e+45 7.40547687e+45\n",
      "  7.40542758e+45 7.40540495e+45]\n",
      " [3.85659622e+45 3.85670255e+45 3.85666372e+45 3.85671298e+45\n",
      "  3.85659605e+45 3.85661660e+45 3.85660261e+45 3.85666462e+45\n",
      "  3.85663895e+45 3.85662716e+45]\n",
      " [4.58895481e+45 4.58908133e+45 4.58903512e+45 4.58909375e+45\n",
      "  4.58895460e+45 4.58897905e+45 4.58896242e+45 4.58903620e+45\n",
      "  4.58900566e+45 4.58899163e+45]\n",
      " [4.93205272e+45 4.93218869e+45 4.93213903e+45 4.93220204e+45\n",
      "  4.93205250e+45 4.93207877e+45 4.93206089e+45 4.93214019e+45\n",
      "  4.93210736e+45 4.93209229e+45]\n",
      " [5.19660343e+45 5.19674670e+45 5.19669438e+45 5.19676076e+45\n",
      "  5.19660320e+45 5.19663088e+45 5.19661204e+45 5.19669560e+45\n",
      "  5.19666101e+45 5.19664513e+45]\n",
      " [4.26296817e+45 4.26308569e+45 4.26304277e+45 4.26309723e+45\n",
      "  4.26296797e+45 4.26299068e+45 4.26297523e+45 4.26304377e+45\n",
      "  4.26301539e+45 4.26300237e+45]\n",
      " [3.89939505e+45 3.89950255e+45 3.89946329e+45 3.89951310e+45\n",
      "  3.89939487e+45 3.89941564e+45 3.89940151e+45 3.89946420e+45\n",
      "  3.89943825e+45 3.89942633e+45]\n",
      " [5.79036461e+45 5.79052424e+45 5.79046594e+45 5.79053991e+45\n",
      "  5.79036434e+45 5.79039519e+45 5.79037420e+45 5.79046730e+45\n",
      "  5.79042876e+45 5.79041106e+45]\n",
      " [5.35520706e+45 5.35535470e+45 5.35530078e+45 5.35536919e+45\n",
      "  5.35520682e+45 5.35523535e+45 5.35521593e+45 5.35530204e+45\n",
      "  5.35526639e+45 5.35525003e+45]\n",
      " [5.86934942e+45 5.86951123e+45 5.86945213e+45 5.86952711e+45\n",
      "  5.86934915e+45 5.86938042e+45 5.86935914e+45 5.86945351e+45\n",
      "  5.86941445e+45 5.86939651e+45]\n",
      " [4.84003386e+45 4.84016730e+45 4.84011856e+45 4.84018039e+45\n",
      "  4.84003364e+45 4.84005943e+45 4.84004188e+45 4.84011970e+45\n",
      "  4.84008749e+45 4.84007269e+45]\n",
      " [6.54548725e+45 6.54566771e+45 6.54560180e+45 6.54568542e+45\n",
      "  6.54548696e+45 6.54552183e+45 6.54549810e+45 6.54560334e+45\n",
      "  6.54555977e+45 6.54553977e+45]\n",
      " [3.64226494e+45 3.64236535e+45 3.64232868e+45 3.64237521e+45\n",
      "  3.64226477e+45 3.64228417e+45 3.64227097e+45 3.64232953e+45\n",
      "  3.64230529e+45 3.64229416e+45]\n",
      " [5.22193660e+45 5.22208056e+45 5.22202798e+45 5.22209470e+45\n",
      "  5.22193636e+45 5.22196418e+45 5.22194525e+45 5.22202921e+45\n",
      "  5.22199445e+45 5.22197849e+45]\n",
      " [5.85585943e+45 5.85602087e+45 5.85596191e+45 5.85603672e+45\n",
      "  5.85585917e+45 5.85589036e+45 5.85586913e+45 5.85596329e+45\n",
      "  5.85592431e+45 5.85590641e+45]\n",
      " [5.77277712e+45 5.77293627e+45 5.77287815e+45 5.77295190e+45\n",
      "  5.77277686e+45 5.77280762e+45 5.77278669e+45 5.77287951e+45\n",
      "  5.77284108e+45 5.77282344e+45]\n",
      " [4.89580769e+45 4.89594266e+45 4.89589336e+45 4.89595591e+45\n",
      "  4.89580746e+45 4.89583355e+45 4.89581580e+45 4.89589452e+45\n",
      "  4.89586193e+45 4.89584696e+45]\n",
      " [5.42442874e+45 5.42457828e+45 5.42452367e+45 5.42459297e+45\n",
      "  5.42442849e+45 5.42445739e+45 5.42443773e+45 5.42452494e+45\n",
      "  5.42448884e+45 5.42447226e+45]\n",
      " [3.06063383e+45 3.06071821e+45 3.06068740e+45 3.06072649e+45\n",
      "  3.06063369e+45 3.06065000e+45 3.06063890e+45 3.06068811e+45\n",
      "  3.06066774e+45 3.06065839e+45]\n",
      " [5.79566663e+45 5.79582641e+45 5.79576806e+45 5.79584210e+45\n",
      "  5.79566637e+45 5.79569724e+45 5.79567623e+45 5.79576942e+45\n",
      "  5.79573084e+45 5.79571313e+45]\n",
      " [5.02836630e+45 5.02850492e+45 5.02845429e+45 5.02851853e+45\n",
      "  5.02836607e+45 5.02839285e+45 5.02837463e+45 5.02845548e+45\n",
      "  5.02842201e+45 5.02840664e+45]\n",
      " [5.82388494e+45 5.82404549e+45 5.82398686e+45 5.82406126e+45\n",
      "  5.82388467e+45 5.82391570e+45 5.82389459e+45 5.82398823e+45\n",
      "  5.82394946e+45 5.82393166e+45]\n",
      " [6.09334922e+45 6.09351720e+45 6.09345585e+45 6.09353369e+45\n",
      "  6.09334894e+45 6.09338140e+45 6.09335931e+45 6.09345728e+45\n",
      "  6.09341672e+45 6.09339810e+45]\n",
      " [5.82077570e+45 5.82093617e+45 5.82087756e+45 5.82095192e+45\n",
      "  5.82077543e+45 5.82080644e+45 5.82078534e+45 5.82087893e+45\n",
      "  5.82084018e+45 5.82082239e+45]\n",
      " [6.13601373e+45 6.13618289e+45 6.13612111e+45 6.13619950e+45\n",
      "  6.13601345e+45 6.13604614e+45 6.13602389e+45 6.13612255e+45\n",
      "  6.13608171e+45 6.13606295e+45]\n",
      " [5.39294477e+45 5.39309344e+45 5.39303914e+45 5.39310804e+45\n",
      "  5.39294452e+45 5.39297325e+45 5.39295370e+45 5.39304041e+45\n",
      "  5.39300452e+45 5.39298803e+45]\n",
      " [4.80580771e+45 4.80594020e+45 4.80589181e+45 4.80595320e+45\n",
      "  4.80580749e+45 4.80583309e+45 4.80581567e+45 4.80589294e+45\n",
      "  4.80586095e+45 4.80584626e+45]\n",
      " [4.97583540e+45 4.97597258e+45 4.97592248e+45 4.97598604e+45\n",
      "  4.97583517e+45 4.97586168e+45 4.97584364e+45 4.97592365e+45\n",
      "  4.97589053e+45 4.97587532e+45]\n",
      " [6.60575200e+45 6.60593411e+45 6.60586760e+45 6.60595198e+45\n",
      "  6.60575170e+45 6.60578689e+45 6.60576294e+45 6.60586915e+45\n",
      "  6.60582518e+45 6.60580499e+45]\n",
      " [4.44053544e+45 4.44065786e+45 4.44061315e+45 4.44066988e+45\n",
      "  4.44053524e+45 4.44055889e+45 4.44054280e+45 4.44061419e+45\n",
      "  4.44058464e+45 4.44057106e+45]]\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(50000, size=32)\n",
    "x = x_train[idx]\n",
    "y = y_train[idx]\n",
    "\n",
    "# print(x.shape)\n",
    "\n",
    "x = x.reshape(32, 3, 32, 32)\n",
    "\n",
    "# print(x.shape)\n",
    "\n",
    "a1 = conv1.forward_pass(x)\n",
    "a2 = pool1.forward_pass(a1)\n",
    "a3 = conv2.forward_pass(a2)\n",
    "a4 = pool2.forward_pass(a3)\n",
    "\n",
    "# cannot flatten this directly at this position\n",
    "a5 = conv3.forward_pass(a4).reshape(32, 4096)\n",
    "# print(a5.shape)\n",
    "a6 = fc1.forward_pass(a5)\n",
    "a7 = fc2.forward_pass(a6)\n",
    "print(a7)\n",
    "# out = softmax(a7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683292a7-87a7-44ea-a31e-53325d31edf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
