{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8962f70f-4af4-4ee1-bec0-1386025fdb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "89749281-9e08-4ec4-99a6-a2da8688d36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_filter(n, s) :\n",
    "      return np.zeros((n, s, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ac502829-f2ba-42f9-a5e5-343c356760d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4907a700-2449-4311-8618-59dc92535afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 3072), (50000,))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set1 = unpickle(\"./content/data_batch_1\")\n",
    "set2 = unpickle(\"./content/data_batch_2\")\n",
    "set3 = unpickle(\"./content/data_batch_3\")\n",
    "set4 = unpickle(\"./content/data_batch_4\")\n",
    "set5 = unpickle(\"./content/data_batch_5\")\n",
    "x_train = np.vstack((set1[b'data'], set2[b'data'], set3[b'data'], set4[b'data'], set5[b'data']))\n",
    "y_train = np.hstack((np.array(set1[b'labels']), np.array(set2[b'labels']), np.array(set3[b'labels']), np.array(set4[b'labels']) ,np.array(set5[b'labels']) ))\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7a549f06-37d5-444f-9896-8c11a6ee1cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(map):    \n",
    "    output_tensor = np.maximum(map, 0)\n",
    "    return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d2be173f-5bb8-4ac5-989c-62be8036a552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling(map, dim):\n",
    "    n_channels = map.shape[0]\n",
    "    map_size = map.shape[1]\n",
    "    output_size = map.shape[1]//dim\n",
    "\n",
    "    return map.reshape(n_channels, output_size, dim, output_size, dim).max(axis=(2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "769cec14-28c1-4507-a30e-494751aec265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(v):\n",
    "    output = np.exp(v)\n",
    "    final_output = output/(np.sum(output))\n",
    "    \n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3cdac14b-9e91-455a-97d0-ad7d980df975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution(sample, kernel):\n",
    "    # assert len(sample.shape) == len(kernel.shape) - 1 # check that the filter and sample dimensions match \n",
    "    kernel_size = kernel.shape[1]\n",
    "    pad = kernel_size//2\n",
    "    n, h, w = sample.shape\n",
    "    \n",
    "    out_sample = np.zeros((n, h+2*pad, w+2*pad))\n",
    "    \n",
    "    for i in range(n):\n",
    "        out_sample[i] = np.pad(sample[i], (pad,), 'constant', constant_values = 0)\n",
    "    sample = out_sample\n",
    "    \n",
    "    size_feature_map = h # output dimension for same convolution\n",
    "    n_out_channels = kernel.shape[0] # number of output channels is the number of filters (for now)\n",
    "\n",
    "    #now we perform the convolution\n",
    "\n",
    "    # initializing the output tensor to zeros\n",
    "    output_tensor = create_filters(n_out_channels, size_feature_map)\n",
    "\n",
    "    # loop for all the kernels\n",
    "    for i in range(n_out_channels):\n",
    "        current_kernel = kernel[i] # get the required kernel\n",
    "\n",
    "        for r in range(size_feature_map): # for the rows\n",
    "            for c in range(size_feature_map): # for the columns\n",
    "                window = sample[:, r : r + kernel_size, c : c + kernel_size] #take the window\n",
    "                value = np.sum(window*current_kernel, axis = None) # multiply with the kernel and sum  up the value\n",
    "                output_tensor[i, r, c] = value # update the result tensor\n",
    "\n",
    "    return output_tensor # return the result tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "8dd32072-3608-46e8-bd35-5a89ba57434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(v):\n",
    "    return (v - np.mean(v))/np.std(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "03c31c62-29a8-4adb-96a7-7ddf7bec9c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 59,  43,  50, ..., 140,  84,  72], dtype=uint8)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image1 = x_train[0]\n",
    "image1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "b60637f5-4c4f-4b8b-adcc-92ef20652c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = image1.reshape(3, 32, 32)\n",
    "image1 = normalise(image1)\n",
    "# image1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "baa20b67-f631-43e3-b64a-0e5fe4b6d41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_kernel = np.random.uniform(low=-1, high=1, size=(32, 3, 3))\n",
    "# conv1_kernel = np.array([[-1,0,1], [-1,0,1], [-1,0,1]])\n",
    "# conv2_kernel = np.random.rand(64, 5, 5)\n",
    "conv2_kernel = np.random.uniform(low=-1, high=1, size=(64, 5, 5))\n",
    "# conv2_kernel = np.array([-1,-1,-1], [0,0,0], [1,1,1])\n",
    "conv3_kernel = np.random.uniform(low=-1, high=1, size=(64, 3, 3))\n",
    "# fc1_weights = np.random.rand(64, 4096)\n",
    "fc1_weights = np.random.uniform(low=-1, high=1, size=(64, 4096))\n",
    "fc2_weights = np.random.uniform(low=-1, high=1, size=(10, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "34c8a3ed-0865-4421-9fc2-70b27d49c6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_out = convolution(image1, conv1_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "539c16cf-92e9-414a-80df-3c2ee670a4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_out_active = relu(conv1_out)\n",
    "# conv1_out_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "82b95c0b-9479-47c5-ad86-f9aa499bac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool1_out = pooling(conv1_out_active, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "d0c974e5-c35f-4756-9467-0dbeb98d774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2_out = convolution(pool1_out, conv2_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "8e400ded-6162-4692-949a-018e26b94f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2_out_active = relu(conv2_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "9ed0a497-86d5-462f-a872-1a65aed15d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool2_out = pooling(conv2_out_active, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "04a7ae46-86b9-4713-b2a1-7a0c751718d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv3_out = normalise(convolution(pool2_out, conv3_kernel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "f7115d2b-29b0-42f0-9db3-9f2d8e49ecf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 8, 8)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv3_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "14dfadc7-7ab3-4145-a506-08cc69d07509",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv3_out_active = relu(conv3_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "b6711bcb-f39d-49f8-8b63-4c6a6bca71d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv3_out_active_flat = conv3_out_active.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "ac702385-73fa-42de-8b83-3da8336254a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv3_out_active_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "7d16508b-b452-4d1c-a726-c0c351f219d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1_out = normalise(fc1_weights @ conv3_out_active_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "6d96ac9b-8138-4e5e-bf4d-99001a6b7272",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1_out_active = relu(fc1_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "91b2166b-44ba-4e10-b63d-0c0a5d0e2039",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc2_out = fc2_weights @ fc1_out_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "d593cf86-8844-4af3-a571-5493cabe8c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.66143763, -1.11905862,  1.30600511,  2.83157772, -2.21200271,\n",
       "       -2.09807378,  2.37526372,  2.002248  , -4.7680273 ,  5.26505505])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc2_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "d96093a4-391c-4845-af62-8f1510efe76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.14744610e-04, 1.40143741e-03, 1.58403766e-02, 7.28304960e-02,\n",
       "       4.69801195e-04, 5.26493268e-04, 4.61464837e-02, 3.17789796e-02,\n",
       "       3.64625252e-05, 8.30154725e-01])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_out = softmax(fc2_out)\n",
    "final_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "3ed67cb3-525e-4928-99ae-cdf43e7f8b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983330df-efc9-4a5c-b64e-7a26aa1e0ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(([[1, 1, 2, 4], [1, -1, 1, -1], [1, 1, 1, 1], [1, -1, 1, -1]], [[2, 2, 2, 0], [2, 0, 2, 2], [0, 2, 2, 2], [2, 2, 0, 2]], [[3, 3, 3, 3], [30, 3, 3, 30], [3, 3, 3, -5], [3, 3, 3, -5]]))\n",
    "b = np.array(([[[5,5,5], [5, 5,5], [5,5,5]], [[5,5,5], [5, 5,5], [5,5,5]], [[5,5,5], [5, 5,5], [5,5,5]]]))\n",
    "# np.pad(a[0], (1,), 'constant', constant_values = 0)\n",
    "convolution(a, b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
