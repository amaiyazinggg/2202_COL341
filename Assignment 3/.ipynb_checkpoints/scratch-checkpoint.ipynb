{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9eeb64c-7ce0-4f9a-8b34-e3e4d06f616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import glob\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eef5bd9c-7917-43b2-b5dc-5b85517759f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left_child = None, right_child = None, info_gain=None, value=None):\n",
    "        self.left_child = left\n",
    "        self.right_child = right\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.info_gain = info_gain\n",
    "        self.value = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d08c5a7e-82bb-4aa6-a4ac-27baa4b2cb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    \n",
    "    def __init__(self, min_samples_split=7, max_depth=10):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.root = None\n",
    "        \n",
    "    def calc_entropy(self, y):\n",
    "        #np.bincount calcultes number of elements in each class\n",
    "        number_of_each_class = np.bincount(np.array(y, dtype=np.int64))\n",
    "        \n",
    "        #These are the probabilities\n",
    "        probabilities = number_of_each_class/len(y)\n",
    "\n",
    "        entropy = 0\n",
    "        \n",
    "        for prob in probabilities:\n",
    "            if prob > 0:\n",
    "                #using the formula for entropy\n",
    "                entropy -= np.log2(prob) * prob\n",
    "                \n",
    "        return entropy\n",
    "    \n",
    "    def information_gain(self, left, right, parent):\n",
    "        p = len(parent)\n",
    "        \n",
    "        #calculate number of entries in the left and right child nodes\n",
    "        l_prob = len(left)/p\n",
    "        r_prob = len(right)/p\n",
    "        \n",
    "        #Using the formula for information gain\n",
    "        gain = self.calc_entropy(parent) - r_prob * self.calc_entropy(right) - l_prob * self.calc_entropy(left)\n",
    "        \n",
    "        return gain\n",
    "    \n",
    "    def find_split(self, x, y):\n",
    "        split_best = {}\n",
    "        gain_best = -1\n",
    "        \n",
    "        rows = x.shape[0]\n",
    "        columns = x.shape[1]\n",
    "        \n",
    "        for feature in range(columns):\n",
    "            \n",
    "            selected_column = x[:, feature]\n",
    "\n",
    "            for threshold in np.unique(selected_column):\n",
    "                \n",
    "                data = np.concatenate((x, y.reshape(1, -1).T), axis=1)\n",
    "                \n",
    "                left_child = [vector for vector in data if vector[feature] <= threshold]\n",
    "                left_child = np.array(left_child)\n",
    "                \n",
    "                right_child = [vector for vector in data if vector[feature] > threshold]\n",
    "                right_child = np.array(right_child)\n",
    "\n",
    "                if len(left_child) > 0 and len(right_child) > 0:\n",
    "                    y = data[:, -1]\n",
    "                    y_left = left_child[:, -1]\n",
    "                    y_right = right_child[:, -1]\n",
    "\n",
    "                    gain = self.information_gain(y_left, y_right, y)\n",
    "                    if gain > gain_best:\n",
    "                        split_best = {\n",
    "                            'feature_index': feature,\n",
    "                            'threshold': threshold,\n",
    "                            'df_left': left_child,\n",
    "                            'df_right': right_child,\n",
    "                            'gain': gain\n",
    "                        }\n",
    "                        gain_best = gain\n",
    "                        \n",
    "        return split_best\n",
    "    \n",
    "    def construct_tree(self, x, y, depth=0):\n",
    "\n",
    "        rows = x.shape[0]\n",
    "        columns = x.shape[1]\n",
    "        \n",
    "        if rows >= self.min_samples_split and depth <= self.max_depth:\n",
    "            \n",
    "            optimal_split = self.find_split(x, y)\n",
    "            if optimal_split['gain'] > 0:\n",
    "\n",
    "                left = self.construct_tree(\n",
    "                    x = optimal_split['df_left'][:, :-1], \n",
    "                    y = optimal_split['df_left'][:, -1], \n",
    "                    depth += 1\n",
    "                )\n",
    "                right = self.construct_tree(\n",
    "                    x = optimal_split['df_right'][:, :-1], \n",
    "                    y = optimal_split['df_right'][:, -1], \n",
    "                    depth += 1)\n",
    "                \n",
    "                return Node(\n",
    "                    feature = optimal_split['feature_index'], \n",
    "                    threshold = optimal_split['threshold'], \n",
    "                    left_child = left, \n",
    "                    right_child = right, \n",
    "                    info_gain = optimal_split['gain'])\n",
    "\n",
    "        return Node( value=Counter(y).most_common(1)[0][0] )\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.root = self.construct_tree(x, y)\n",
    "        \n",
    "    def predict_helper(self, my_node, x):\n",
    "        #value is Not None only for leaf nodes\n",
    "        if my_node.value != None:\n",
    "            return my_node.value\n",
    "        \n",
    "        #take that particular feature of the entry\n",
    "        compare_this = x[my_node.feature]\n",
    "        \n",
    "        #check on which side of the threshold it is\n",
    "        if compare_this <= my_node.threshold:\n",
    "            return self.predict_helper(my_node.left_child, x)\n",
    "        else:\n",
    "            return self.predict_helper(my_node.right_child, x)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        y_prediction = [self.predict_helper(self.root, i) for i in x]\n",
    "        return y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26537d7c-61cf-4a91-9185-3522546a7653",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = glob.glob(\"data/train/person/*.png\")\n",
    "cv_img = []\n",
    "for img in path:\n",
    "    n = np.array(cv.imread(img).flatten())\n",
    "    cv_img.append(n)\n",
    "path = glob.glob(\"data/train/car/*.png\")\n",
    "for img in path:\n",
    "    n = np.array(cv.imread(img).flatten())\n",
    "    cv_img.append(n)\n",
    "path = glob.glob(\"data/train/dog/*.png\")\n",
    "for img in path:\n",
    "    n = np.array(cv.imread(img).flatten())\n",
    "    cv_img.append(n)\n",
    "path = glob.glob(\"data/train/airplane/*.png\")\n",
    "for img in path:\n",
    "    n = np.array(cv.imread(img).flatten())\n",
    "    cv_img.append(n)\n",
    "x_train = np.array(cv_img)\n",
    "y_ones = np.ones(500)\n",
    "y_zeros = np.zeros(1500)\n",
    "y_train = np.hstack((y_ones, y_zeros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6a72359-e685-4e42-a135-1a917d723eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = glob.glob(\"data/validation/person/*.png\")\n",
    "cv_img = []\n",
    "for img in path:\n",
    "    n = np.array(cv.imread(img).flatten())\n",
    "    cv_img.append(n)\n",
    "path = glob.glob(\"data/validation/car/*.png\")\n",
    "for img in path:\n",
    "    n = np.array(cv.imread(img).flatten())\n",
    "    cv_img.append(n)\n",
    "path = glob.glob(\"data/validation/dog/*.png\")\n",
    "for img in path:\n",
    "    n = np.array(cv.imread(img).flatten())\n",
    "    cv_img.append(n)\n",
    "path = glob.glob(\"data/validation/airplane/*.png\")\n",
    "for img in path:\n",
    "    n = np.array(cv.imread(img).flatten())\n",
    "    cv_img.append(n)\n",
    "x_validation = np.array(cv_img)\n",
    "y_validation = np.hstack((np.ones(100), np.zeros(300)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3f4e5c-f5fb-4586-af14-97df8e9e4471",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "y_validation_predicted = model.predict(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069be07e-be3b-4ad3-999e-bc37f6ad47a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.metrics.accuracy_score(y_validation, y_validation_predicted)*100)\n",
    "print(sklearn.metrics.precision_score(y_validation, y_validation_predicted)*100)\n",
    "print(sklearn.metrics.recall_score(y_validation, y_validation_predicted)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b073ab44-45c9-4817-9268-9226935e7c96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
